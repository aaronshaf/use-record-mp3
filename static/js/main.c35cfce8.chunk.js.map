{"version":3,"sources":["../../src/convert.ts","../../src/index.ts","../../src/utils.ts","processing.ts","App.tsx","index.tsx"],"names":["outBuffer","Uint8Array","AudioContext","window","useState","isRecording","setIsRecording","isRecordingPaused","setisRecordingPaused","mediaStream","setMediaStream","recorder","setRecorder","recordingLength","useRef","leftChannel","channelData","setChannelData","audioContext","audioTracks","stream","hasAudioTrack","encoderOptions","capabilities","pcm_l","blob","setBlob","blobUrl","setBlobUrl","encoderPromise","useMemo","createMp3Encoder","useEffect","encoder","options","sampleRate","channels","bitrate","vbrQuality","offset","moreData","mp3Data","newBuffer","result","mp3Blob","Blob","type","mp3BlobUrl","URL","useConvert","data","channelBuffer","Float32Array","i","buffer","flattenArray","processing","startRecording","context","e","leftChannelData","mediaStream2","stopRecording","pauseRecording","average","array","reduce","total","value","sum","length","trim","rollingAverageArray","index","push","Math","abs","shift","slice","trimEndingSilence","trimBeginningSilence","App","audio","constraints","useUserMedia","device","getAudioTracks","label","useRecordMp3","post","chartComponents","rawData","blockSize","floor","filteredData","blockStart","j","filterData","map","number","key","style","width","height","backgroundColor","className","ow","disabled","onClick","controls","src","display","alignItems","color","position","href","ReactDOM","render","document","getElementById"],"mappings":"uRAIA,IAAIA,EAAY,IAAIC,WAAW,SCCzBC,EAAeC,qBAAwBA,OAA7C,mB,EAMqB,SAAC,EAAD,K,MAKmBC,oBAAS,GAAxCC,OAAaC,O,EAC8BF,oBAAS,GAApDG,OAAmBC,O,EAItBJ,mBAAQ,MAFVK,OACAC,O,EAE8BN,mBAAQ,MAAjCO,OAAUC,OACXC,EAAkBC,iBAAxB,GACMC,EAAcD,iBAApB,I,EAEsCV,mBAAQ,MAAvCY,OAAaC,OACdC,EAAeJ,iBAArB,MAEMK,EAAcC,GAAUA,EAA9B,iBACMC,GAAgB,OAAAF,QAAW,IAAXA,OAAA,EAAAA,EAAA,QAAtB,EAEA,GACoB,kBAAXC,GAAP,IAECE,EAHH,WAIE,OACMC,EAAeJ,KAArB,kBAEAG,uBAA4BC,EAA5BD,+BAA4BC,EAA5BD,I,MDjCe,SAACE,EAAD,G,MACOpB,mBAAQ,MAAzBqB,OAAMC,O,EACiBtB,mBAAQ,MAA/BuB,OAASC,OACVC,EAAiBC,mBAAQ,kBAAMC,gBAArC,IA4DA,OA1DAC,qBAAU,WACR,GACAH,QAAoB,YAClBI,YACEC,EAAA,QACI,CACEC,WAAYD,cADd,KAEEE,SAAUF,YAFZ,EAGEG,QAASH,EAAQG,SAEnB,CACEF,WAAYD,cADd,KAEEE,SAAUF,YAFZ,EAGEI,WAAYJ,cAAsB,IAO1C,IAHA,IAAIK,EAAJ,EACIC,GAAJ,IAEa,CACX,IAAMC,EAAUD,EACZP,SAAe,CADK,IAMpBA,EANJ,WASA,GAAIQ,WAA0BzC,EAA9B,OAAgD,CAC9C,IAAM0C,EAAY,IAAIzC,WAAWwC,SAAjC,GACAC,SACA1C,IAMF,GAHAA,WACAuC,GAAUE,EAAVF,QAEA,EACE,MAGFC,KAGF,IAAMG,EAAS,IAAI1C,WAAWD,EAAf,SAAf,GAEM4C,EAAU,IAAIC,KAAK,CAAC,IAAI5C,WAAW0C,GAAzB,QAA0C,CACxDG,KAAM,eAEFC,EAAaC,oBAAnB,GAEAtB,KACAE,UAED,CAxDHI,IA0DO,CAACL,EAAR,GC3B6BsB,CAAWjC,EAAaM,GAA9CK,OAASF,OA2EhB,OAfAO,qBAAU,WACR,QAAI3B,GACEM,MAA2BO,EAA/B,QAAqD,CACnDP,GAAYA,aAAoBO,UAAhCP,aACAF,GAAeA,aAAfA,GACA,IAAMyC,E,SC3GeC,EAAoBtC,GAG/C,IAFA,IAAI8B,EAAS,IAAIS,aAAjB,GACIb,EAAJ,EACSc,EAAT,EAAgBA,EAAIF,EAApB,OAA0CE,IAAK,CAC7C,IAAIC,EAASH,EAAb,GACAR,WACAJ,GAAUe,EAAVf,OAEF,SDmGmBgB,CAAaxC,EAAD,QAAsBF,EAA/C,SACA,OAAI2C,QAAJ,IAAIA,KAAJ,KACEvC,EAAeuC,OAAfvC,IAEAA,QAIL,CAbHe,IAeO,CACL3B,YADK,EAELE,kBAFK,EAGLkD,eA5EqB,WACrB,MAEAnD,MACA,IACEO,YACAE,cAEFP,MAEAU,UAAuB,IAAIhB,EAAa,CACtCiC,WAAYb,EAAea,aAE7B,IAIA,EAJMuB,EAAUxC,EAAhB,SAMEP,EADE+C,EAAJ,sBACaA,wBAxDjB,KACA,EACA,GA4DkBA,uBA9DlB,KACA,EACA,IAmEI/C,eAA0B,SAAUgD,GAClC,IAAMC,EAAkB,IAAIR,aAAaO,6BAAzC,IACA5C,kBAIAF,UAA0BA,UA3EhC,MA8EID,KACA,IAAMiD,EAAeH,0BAArB,GACAhD,KACAmD,aACAlD,UAAiB+C,EAAjB/C,eAgCAmD,cAxBoB,WACpBxD,MACAE,OAuBAuD,eA9BqB,WACrBzD,MACAE,OA6BAmB,QANK,EAOLF,KAPK,EAQLT,gB,wBE3HEgD,EAAU,SAACC,GAAD,OAFJ,SAACA,GAAD,OACVA,EAAMC,QAAO,SAACC,EAAOC,GAAR,OAAkBD,EAAQC,IAAO,GACNC,CAAIJ,GAASA,EAAMK,QA0ChDC,EAAO,SAACrB,GAEnB,OArB+B,SAACA,GAGhC,IAFA,IACMsB,EAAsB,GACnBC,EAAQvB,EAAKoB,OAAQG,EAAQ,EAAGA,IAMvC,GALAD,EAAoBE,KAAKC,KAAKC,IAAI1B,EAAKuB,KACnCD,EAAoBF,OAzBC,IA0BvBE,EAAoBK,QAGlBb,EAAQQ,GARS,IASnB,OAAOtB,EAAK4B,MACV,EACAL,EAAQvB,EAAKoB,OAjCH,IAiCwBG,EAjCxB,IAiC4CvB,EAAKoB,QAIjE,OAAOpB,EAIa6B,CAnCc,SAAC7B,GAGnC,IAFA,IACMsB,EAAsB,GACnBC,EAAQ,EAAGA,EAAQvB,EAAKoB,OAAQG,IAKvC,GAJAD,EAAoBE,KAAKC,KAAKC,IAAI1B,EAAKuB,KACnCD,EAAoBF,OAVC,IAWvBE,EAAoBK,QAElBb,EAAQQ,GAPS,IAQnB,OAAOtB,EAAK4B,MAAML,EAfN,IAe0BA,EAf1B,IAe8C,GAG9D,OAAOvB,EAuB+B8B,CAAqB9B,K,ifCrC7D,IAmHe+B,EA9FH,WAAO,IAAD,EACM7E,mBAAiC,CACrD8E,OAAO,IADFC,EADS,oBAIR/D,EAAWgE,IAAaD,GAAxB/D,OAEFiE,EAASjE,GAAUA,EAAOkE,iBAAiB,GAAGC,MANpC,EAgBZC,EACFpE,EACA,CACEe,WAAY,KACZC,SAAU,EAEVE,WAAY,GAEd,CACEmD,KAAMlB,IAhBRlE,EATc,EASdA,YACAE,EAVc,EAUdA,kBACAkD,EAXc,EAWdA,eACAK,EAZc,EAYdA,cACAC,EAbc,EAadA,eACApC,EAdc,EAcdA,QACAX,EAfc,EAedA,YAcI0E,GADQ1E,EAjDG,SAAC2E,GAKlB,IAHA,IACMC,EAAYjB,KAAKkB,MAAMF,EAAQrB,OADrB,KAEVwB,EAAe,GACZzC,EAAI,EAAGA,EAHA,IAGaA,IAAK,CAGhC,IAFA,IAAI0C,EAAaH,EAAYvC,EACzBgB,EAAM,EACD2B,EAAI,EAAGA,EAAIJ,EAAWI,IAC7B3B,GAAYM,KAAKC,IAAIe,EAAQI,EAAaC,IAE5CF,EAAapB,KAAKL,EAAMuB,GAE1B,OAAOE,EAoCqBG,CAAWjF,GAAe,IACxBkF,KAAI,SAACC,EAAgB1B,GACjD,OACE,yBACE2B,IAAK3B,EACL4B,MAAO,CACLC,MAAO,OACPC,OAAO,GAAD,OAAc,IAATJ,EAAL,KACNK,gBAAiB,YAMzB,OACE,yBAAKC,UAAWC,YAAF,MACZ,4BACEC,SAAUtG,EACVoG,UAAWC,YAAF,KACTE,QAASnD,GAHX,UAOA,4BACEkD,WAAYtG,IAAiBA,GAAeE,GAC5CkG,UAAWC,YAAF,KACTE,QAAS9C,GAHX,QAOA,4BACE6C,UAAWtG,IAAgBE,EAC3BkG,UAAWC,YAAF,KACTE,QAASrG,EAAoBkD,EAAiBM,GAHhD,SAOCpC,GACC,yBAAK8E,UAAWC,YAAF,MACZ,2BAAOG,UAAQ,EAACC,IAAKnF,IACrB,yBACE0E,MAAO,CACLU,QAAS,OACTC,WAAY,SACZV,MAAO,QACPC,OAAQ,UAGTb,IAKNL,EAED,kBAAC,IAAD,CACE4B,MAAM,QACNC,SAAS,QACTC,KAAK,+CAHP,iBC1GNC,IAASC,OAAO,kBAAC,EAAD,MAASC,SAASC,eAAe,W","file":"static/js/main.c35cfce8.chunk.js","sourcesContent":["import { useEffect, useState, useMemo } from \"react\";\nimport { createMp3Encoder } from \"wasm-media-encoders\";\nimport { EncoderOptions } from \"./typings\";\n\nlet outBuffer = new Uint8Array(1024 * 1024);\n\nconst useConvert = (pcm_l: any, options: EncoderOptions) => {\n  const [blob, setBlob] = useState<Blob | null>(null);\n  const [blobUrl, setBlobUrl] = useState<string | null>(null);\n  const encoderPromise = useMemo(() => createMp3Encoder(), []);\n\n  useEffect(() => {\n    if (!pcm_l) return;\n    encoderPromise.then((encoder) => {\n      encoder.configure(\n        options.bitrate\n          ? {\n              sampleRate: options.sampleRate || 48000,\n              channels: options.channels || 1,\n              bitrate: options.bitrate,\n            }\n          : {\n              sampleRate: options.sampleRate || 48000,\n              channels: options.channels || 1,\n              vbrQuality: options.vbrQuality || 2,\n            }\n      );\n\n      let offset = 0;\n      let moreData = true;\n\n      while (true) {\n        const mp3Data = moreData\n          ? encoder.encode([\n              pcm_l /* Float32Array of left channel PCM data */,\n              // pcm_r /* Float32Array of right channel PCM data */,\n            ])\n          : /* finalize() returns the last few frames */\n            encoder.finalize();\n\n        /* mp3Data is a Uint8Array that is still owned by the encoder and MUST be copied */\n        if (mp3Data.length + offset > outBuffer.length) {\n          const newBuffer = new Uint8Array(mp3Data.length + offset);\n          newBuffer.set(outBuffer);\n          outBuffer = newBuffer;\n        }\n\n        outBuffer.set(mp3Data, offset);\n        offset += mp3Data.length;\n\n        if (!moreData) {\n          break;\n        }\n\n        moreData = false;\n      }\n\n      const result = new Uint8Array(outBuffer.buffer, 0, offset);\n\n      const mp3Blob = new Blob([new Uint8Array(result).buffer], {\n        type: \"audio/mpeg\",\n      });\n      const mp3BlobUrl = URL.createObjectURL(mp3Blob);\n\n      setBlob(mp3Blob);\n      setBlobUrl(mp3BlobUrl);\n    });\n  }, [pcm_l]);\n\n  return [blobUrl, blob];\n};\n\nexport default useConvert;\n","import { flattenArray } from \"./utils\";\nimport useConvert from \"./convert\";\nimport { useState, useEffect, useRef } from \"react\";\nimport { EncoderOptions } from \"./typings\";\n\nconst AudioContext = window.AudioContext || (window as any).webkitAudioContext;\n\nconst bufferSize = 2048;\nconst numberOfInputChannels = 1;\nconst numberOfOutputChannels = 1;\n\nconst useRecordMp3 = (\n  stream: MediaStream,\n  encoderOptions: EncoderOptions,\n  processing?: { post?: (data: Float32Array) => Float32Array }\n) => {\n  const [isRecording, setIsRecording] = useState(false);\n  const [isRecordingPaused, setisRecordingPaused] = useState(false);\n  const [\n    mediaStream,\n    setMediaStream,\n  ] = useState<MediaStreamAudioSourceNode | null>(null);\n  const [recorder, setRecorder] = useState<ScriptProcessorNode | null>(null);\n  const recordingLength = useRef(0);\n  const leftChannel = useRef<Array<Float32Array>>([]);\n\n  const [channelData, setChannelData] = useState<Float32Array | null>(null);\n  const audioContext = useRef<AudioContext | null>(null);\n\n  const audioTracks = stream && stream.getAudioTracks();\n  const hasAudioTrack = audioTracks?.length > 0;\n\n  if (\n    typeof stream === \"object\" &&\n    hasAudioTrack &&\n    !encoderOptions.sampleRate\n  ) {\n    const capabilities = audioTracks[0].getCapabilities();\n    // TODO: stop mutating object?\n    encoderOptions.sampleRate = capabilities.sampleRate?.max;\n  }\n\n  const [blobUrl, blob]: any = useConvert(channelData, encoderOptions);\n\n  const startRecording = () => {\n    if (!stream) return;\n\n    setIsRecording(true);\n    if (!isRecordingPaused) {\n      recordingLength.current = 0;\n      leftChannel.current = [];\n    }\n    setisRecordingPaused(false);\n\n    audioContext.current = new AudioContext({\n      sampleRate: encoderOptions.sampleRate,\n    });\n    const context = audioContext.current;\n\n    // https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createScriptProcessor\n    // bufferSize: the onaudioprocess event is called when the buffer is full\n    let recorder: ScriptProcessorNode;\n    if (context.createScriptProcessor) {\n      recorder = context.createScriptProcessor(\n        bufferSize,\n        numberOfInputChannels,\n        numberOfOutputChannels\n      );\n    } else {\n      recorder = (context as any).createJavaScriptNode(\n        bufferSize,\n        numberOfInputChannels,\n        numberOfOutputChannels\n      );\n    }\n\n    recorder.onaudioprocess = function (e: any) {\n      const leftChannelData = new Float32Array(e.inputBuffer.getChannelData(0));\n      leftChannel.current.push(leftChannelData);\n      // rightchannel.push(\n      //   new Float32Array(e.inputBuffer.getChannelData(1))\n      // );\n      recordingLength.current = recordingLength.current + bufferSize;\n    };\n\n    setRecorder(recorder);\n    const mediaStream2 = context.createMediaStreamSource(stream);\n    setMediaStream(mediaStream2);\n    mediaStream2.connect(recorder);\n    recorder.connect(context.destination);\n  };\n\n  const pauseRecording = () => {\n    setIsRecording(false);\n    setisRecordingPaused(true);\n  };\n\n  const stopRecording = () => {\n    setIsRecording(false);\n    setisRecordingPaused(false);\n  };\n\n  useEffect(() => {\n    if (isRecording === false) {\n      if (recorder && mediaStream && audioContext.current) {\n        recorder && recorder.disconnect(audioContext.current.destination);\n        mediaStream && mediaStream.disconnect(recorder);\n        const data = flattenArray(leftChannel.current, recordingLength.current);\n        if (processing?.post) {\n          setChannelData(processing.post(data));\n        } else {\n          setChannelData(data);\n        }\n      }\n    }\n  }, [isRecording]);\n\n  return {\n    isRecording,\n    isRecordingPaused,\n    startRecording,\n    stopRecording,\n    pauseRecording,\n    blobUrl,\n    blob,\n    channelData,\n  };\n};\n\nexport default useRecordMp3;\n","export function flattenArray(channelBuffer: any, recordingLength: number) {\n  var result = new Float32Array(recordingLength);\n  var offset = 0;\n  for (var i = 0; i < channelBuffer.length; i++) {\n    var buffer = channelBuffer[i];\n    result.set(buffer, offset);\n    offset += buffer.length;\n  }\n  return result;\n}\n\nexport function convertToArrayBuffer(blob: Blob) {\n  const url = URL.createObjectURL(blob);\n\n  return fetch(url).then((response) => {\n    return response.arrayBuffer();\n  });\n}\n\n// function process(data) {\n//   const blob = new Blob(data);\n\n//   convertToArrayBuffer(blob)\n//     .then((arrayBuffer) => audioContext.decodeAudioData(arrayBuffer))\n//     .then((audioBuffer) => {\n//       const channelData = audioBuffer.getChannelData(0);\n//       setChannelData(channelData);\n//     });\n// }\n","const sum = (array: Array<number>) =>\n  array.reduce((total, value) => total + value, 0);\nconst average = (array: Array<number>) => sum(array) / array.length;\n\nconst TRIM_SIZE = 6000;\nconst ROLLING_AVERAGE_SIZE = 50;\n\n// fruits.shift() take from front\n// fruits.push()\n\nexport const trimBeginningSilence = (data: Float32Array) => {\n  const TRIM_THRESHOLD = 0.02;\n  const rollingAverageArray = [];\n  for (let index = 0; index < data.length; index++) {\n    rollingAverageArray.push(Math.abs(data[index]));\n    if (rollingAverageArray.length > ROLLING_AVERAGE_SIZE) {\n      rollingAverageArray.shift();\n    }\n    if (average(rollingAverageArray) > TRIM_THRESHOLD) {\n      return data.slice(index > TRIM_SIZE ? index - TRIM_SIZE : 0);\n    }\n  }\n  return data;\n};\n\nexport const trimEndingSilence = (data: Float32Array) => {\n  const TRIM_THRESHOLD = 0.01;\n  const rollingAverageArray = [];\n  for (let index = data.length; index > 0; index--) {\n    rollingAverageArray.push(Math.abs(data[index]));\n    if (rollingAverageArray.length > ROLLING_AVERAGE_SIZE) {\n      rollingAverageArray.shift();\n    }\n\n    if (average(rollingAverageArray) > TRIM_THRESHOLD) {\n      return data.slice(\n        0,\n        index < data.length - TRIM_SIZE ? index + TRIM_SIZE : data.length\n      );\n    }\n  }\n  return data;\n};\n\nexport const trim = (data: Float32Array) => {\n  const trimmedData = trimEndingSilence(trimBeginningSilence(data));\n  return trimmedData;\n};\n","import React, { useState } from \"react\";\nimport useUserMedia from \"react-use-user-media\";\nimport useRecordMp3 from \"use-record-mp3\";\nimport ow from \"oceanwind\";\nimport GitHubRibbon from \"react-github-fork-ribbon\";\nimport { trim } from \"./processing\";\n\n// https://css-tricks.com/making-an-audio-waveform-visualizer-with-vanilla-javascript/\nconst filterData = (rawData: any) => {\n  // const rawData = audioBuffer.getChannelData(0); // We only need to work with one channel of data\n  const samples = 1000; // Number of samples we want to have in our final data set\n  const blockSize = Math.floor(rawData.length / samples); // the number of samples in each subdivision\n  const filteredData = [];\n  for (let i = 0; i < samples; i++) {\n    let blockStart = blockSize * i; // the location of the first sample in the block\n    let sum = 0;\n    for (let j = 0; j < blockSize; j++) {\n      sum = sum + Math.abs(rawData[blockStart + j]); // find the sum of all the samples in the block\n    }\n    filteredData.push(sum / blockSize); // divide the sum by the block size to get the average\n  }\n  return filteredData;\n};\n\n// const normalizeData = (filteredData: any) => {\n//   const multiplier = Math.pow(Math.max(...filteredData), -1)\n//   return filteredData.map((n: any) => n * multiplier)\n// }\n\nconst App = () => {\n  const [constraints] = useState<MediaStreamConstraints>({\n    audio: true,\n  });\n  const { stream } = useUserMedia(constraints);\n\n  const device = stream && stream.getAudioTracks()[0].label;\n\n  const {\n    isRecording,\n    isRecordingPaused,\n    startRecording,\n    stopRecording,\n    pauseRecording,\n    blobUrl,\n    channelData,\n  } = useRecordMp3(\n    stream,\n    {\n      sampleRate: 48000,\n      channels: 1,\n      // bitrate: 96,\n      vbrQuality: 2,\n    },\n    {\n      post: trim,\n    }\n  );\n  const chart = channelData ? filterData(channelData) : [];\n  const chartComponents = chart.map((number: number, index: number) => {\n    return (\n      <div\n        key={index}\n        style={{\n          width: \"0.1%\",\n          height: `${number * 100}%`,\n          backgroundColor: \"red\",\n        }}\n      ></div>\n    );\n  });\n\n  return (\n    <div className={ow`p-6`}>\n      <button\n        disabled={isRecording}\n        className={ow`px-4 mr-1 py-2 border border-black rounded text-lg`}\n        onClick={startRecording}\n      >\n        Record\n      </button>\n      <button\n        disabled={!(isRecording || (!isRecording && isRecordingPaused))}\n        className={ow`px-4 mr-1 py-2 border border-black rounded text-lg`}\n        onClick={stopRecording}\n      >\n        Stop\n      </button>\n      <button\n        disabled={!isRecording && !isRecordingPaused}\n        className={ow`px-4 py-2 border border-black rounded text-lg`}\n        onClick={isRecordingPaused ? startRecording : pauseRecording}\n      >\n        Pause\n      </button>\n      {blobUrl && (\n        <div className={ow`pt-4`}>\n          <audio controls src={blobUrl}></audio>\n          <div\n            style={{\n              display: \"flex\",\n              alignItems: \"center\",\n              width: \"300px\",\n              height: \"100px\",\n            }}\n          >\n            {chartComponents}\n          </div>\n        </div>\n      )}\n\n      {device}\n\n      <GitHubRibbon\n        color=\"black\"\n        position=\"right\"\n        href=\"https://github.com/aaronshaf/use-record-mp3\"\n      >\n        GitHub repo\n      </GitHubRibbon>\n    </div>\n  );\n};\n\nexport default App;\n","import \"./index.css\";\n\nimport React from \"react\";\nimport ReactDOM from \"react-dom\";\nimport App from \"./App\";\n\nReactDOM.render(<App />, document.getElementById(\"root\"));\n"],"sourceRoot":""}