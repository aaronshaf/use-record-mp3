{"version":3,"sources":["../../src/convert.ts","../../src/index.ts","../../src/utils.ts","App.tsx","index.tsx"],"names":["outBuffer","Uint8Array","AudioContext","window","stream","useState","isRecording","setIsRecording","mediaStream","setMediaStream","recorder","setRecorder","recordingLength","useRef","leftChannel","channelData","setChannelData","audioContext","pcm_l","blob","setBlob","blobUrl","setBlobUrl","encoderPromise","useMemo","createMp3Encoder","useEffect","encoder","sampleRate","channels","vbrQuality","offset","moreData","mp3Data","newBuffer","result","mp3Blob","Blob","type","mp3BlobUrl","URL","useConvert","context","e","leftChannelData","Float32Array","mediaStream2","data","channelBuffer","i","buffer","flattenArray","constraints","audio","channelCount","App","useUserMedia","useRecordMp3","chartComponents","rawData","blockSize","Math","floor","length","filteredData","blockStart","sum","j","abs","push","filterData","map","number","index","key","style","width","height","backgroundColor","onClick","controls","src","display","alignItems","ReactDOM","render","document","getElementById"],"mappings":"8MAGA,IAAIA,EAAY,IAAIC,WAAW,SCCzBC,EAAeC,qBAAwBA,OAA7C,mB,EAMqB,SAACC,G,MACkBC,oBAAS,GAAxCC,OAAaC,O,EAKhBF,mBAAQ,MAFVG,OACAC,O,EAE8BJ,mBAAQ,MAAjCK,OAAUC,OACXC,EAAkBC,iBAAxB,GACMC,EAAcD,iBAApB,I,EAEsCR,mBAAQ,MAAvCU,OAAaC,OACdC,EAAeJ,iBAArB,M,EDjBiB,SAACK,G,MACMb,mBAAQ,MAAzBc,OAAMC,O,EACiBf,mBAAQ,MAA/BgB,OAASC,OACVC,EAAiBC,mBAAQ,kBAAMC,gBAArC,IAoDA,OAlDAC,qBAAU,WACR,GACAH,QAAoB,YAClBI,YAAkB,CAChBC,WADgB,KAEhBC,SAFgB,EAGhBC,WAAY,IAMd,IAHA,IAAIC,EAAJ,EACIC,GAAJ,IAEa,CACX,IAAMC,EAAUD,EACZL,SAAe,CADK,IAMpBA,EANJ,WASA,GAAIM,WAA0BjC,EAA9B,OAAgD,CAC9C,IAAMkC,EAAY,IAAIjC,WAAWgC,SAAjC,GACAC,SACAlC,IAMF,GAHAA,WACA+B,GAAUE,EAAVF,QAEA,EACE,MAGFC,KAGF,IAAMG,EAAS,IAAIlC,WAAWD,EAAf,SAAf,GAEMoC,EAAU,IAAIC,KAAK,CAAC,IAAIpC,WAAWkC,GAAzB,QAA0C,CACxDG,KAAM,eAEFC,EAAaC,oBAAnB,GAEApB,KACAE,UAED,CAhDHI,IAkDO,CAACL,EAAR,GCrC6BoB,CAAW1B,GAAjCM,OAASF,OAoDhB,OAlDAO,qBAAU,WACR,GAAIpB,GAAJ,EAA2B,CACzBU,QAEAC,UAAuB,IAAvBA,EACA,IAIA,EAJMyB,EAAUzB,EAAhB,SAMEP,EADEgC,EAAJ,sBACaA,wBA9BnB,KACA,EACA,GAkCoBA,uBApCpB,KACA,EACA,IAyCMhC,eAA0B,SAAUiC,GAClC,IAAMC,EAAkB,IAAIC,aAC1BF,6BADF,IAGA7B,kBAIAF,UAA0BA,UAnDlC,MAsDMD,KACA,IAAMmC,EAAeJ,0BAArB,GACAjC,KACAqC,aACApC,UAAiBgC,EAAjBhC,kBACK,QAAIJ,GACLI,MAA2BO,EAA/B,QAAqD,CACnDP,GAAYA,aAAoBO,UAAhCP,aACAF,GAAeA,aAAfA,GACA,IAAMuC,E,SCrEeC,EAAoBpC,GAG/C,IAFA,IAAIuB,EAAS,IAAIU,aAAjB,GACId,EAAJ,EACSkB,EAAT,EAAgBA,EAAID,EAApB,OAA0CC,IAAK,CAC7C,IAAIC,EAASF,EAAb,GACAb,WACAJ,GAAUmB,EAAVnB,OAEF,SD6DmBoB,CAAarC,EAAD,QAAsBF,EAA/C,SACAI,QAGH,CAhDHU,IAkDO,CAAEpB,YAAF,EAAeC,eAAf,EAA+Bc,QAA/B,EAAwCF,KAAxC,EAA8CJ,gBEvEjDqC,EAAc,CAElBC,MAAO,CAGLC,aAAc,IAiEHC,EAvCH,WAAO,IACTnD,EAAWoD,IAAaJ,GAAxBhD,OADQ,EAE8CqD,EAC5DrD,GADME,EAFQ,EAERA,YAAaC,EAFL,EAEKA,eAAgBc,EAFrB,EAEqBA,QAASN,EAF9B,EAE8BA,YAKxC2C,GADQ3C,EA3BG,SAAC4C,GAKlB,IAHA,IACMC,EAAYC,KAAKC,MAAMH,EAAQI,OADrB,KAEVC,EAAe,GACZf,EAAI,EAAGA,EAHA,IAGaA,IAAK,CAGhC,IAFA,IAAIgB,EAAaL,EAAYX,EACzBiB,EAAM,EACDC,EAAI,EAAGA,EAAIP,EAAWO,IAC7BD,GAAYL,KAAKO,IAAIT,EAAQM,EAAaE,IAE5CH,EAAaK,KAAKH,EAAMN,GAE1B,OAAOI,EAcqBM,CAAWvD,GAAe,IACxBwD,KAAI,SAACC,EAAgBC,GACjD,OACE,yBACEC,IAAKD,EACLE,MAAO,CACLC,MAAO,OACPC,OAAO,GAAD,OAAc,IAATL,EAAL,KACNM,gBAAiB,YAKzB,OACE,6BACE,4BAAQC,QAAS,kBAAMxE,GAAgBD,KACpCA,EAAc,OAAS,UAEzBe,GAAW,2BAAO2D,UAAQ,EAACC,IAAK5D,IACjC,yBACEsD,MAAO,CACLO,QAAS,OACTC,WAAY,SACZP,MAAO,QACPC,OAAQ,UAGTnB,KC9DT0B,IAASC,OAAO,kBAAC,EAAD,MAASC,SAASC,eAAe,U","file":"static/js/main.5b88ec9b.chunk.js","sourcesContent":["import { useEffect, useState, useMemo } from 'react'\nimport { createMp3Encoder } from 'wasm-media-encoders'\n\nlet outBuffer = new Uint8Array(1024 * 1024)\n\nconst useConvert = (pcm_l: any) => {\n  const [blob, setBlob] = useState<Blob | null>(null)\n  const [blobUrl, setBlobUrl] = useState<string | null>(null)\n  const encoderPromise = useMemo(() => createMp3Encoder(), [])\n\n  useEffect(() => {\n    if (!pcm_l) return\n    encoderPromise.then((encoder) => {\n      encoder.configure({\n        sampleRate: 48000,\n        channels: 1,\n        vbrQuality: 1\n      })\n\n      let offset = 0\n      let moreData = true\n\n      while (true) {\n        const mp3Data = moreData\n          ? encoder.encode([\n              pcm_l /* Float32Array of left channel PCM data */\n              // pcm_r /* Float32Array of right channel PCM data */,\n            ])\n          : /* finalize() returns the last few frames */\n            encoder.finalize()\n\n        /* mp3Data is a Uint8Array that is still owned by the encoder and MUST be copied */\n        if (mp3Data.length + offset > outBuffer.length) {\n          const newBuffer = new Uint8Array(mp3Data.length + offset)\n          newBuffer.set(outBuffer)\n          outBuffer = newBuffer\n        }\n\n        outBuffer.set(mp3Data, offset)\n        offset += mp3Data.length\n\n        if (!moreData) {\n          break\n        }\n\n        moreData = false\n      }\n\n      const result = new Uint8Array(outBuffer.buffer, 0, offset)\n\n      const mp3Blob = new Blob([new Uint8Array(result).buffer], {\n        type: 'audio/mpeg'\n      })\n      const mp3BlobUrl = URL.createObjectURL(mp3Blob)\n\n      setBlob(mp3Blob)\n      setBlobUrl(mp3BlobUrl)\n    })\n  }, [pcm_l])\n\n  return [blobUrl, blob]\n}\n\nexport default useConvert\n","import { flattenArray } from './utils'\nimport useConvert from './convert'\nimport { useState, useEffect, useRef } from 'react'\n\nconst AudioContext = window.AudioContext || (window as any).webkitAudioContext\n\nconst bufferSize = 2048\nconst numberOfInputChannels = 1\nconst numberOfOutputChannels = 1\n\nconst useRecordMp3 = (stream: any) => {\n  const [isRecording, setIsRecording] = useState(false)\n\n  const [\n    mediaStream,\n    setMediaStream\n  ] = useState<MediaStreamAudioSourceNode | null>(null)\n  const [recorder, setRecorder] = useState<ScriptProcessorNode | null>(null)\n  const recordingLength = useRef(0)\n  const leftChannel = useRef<Array<Float32Array>>([])\n\n  const [channelData, setChannelData] = useState<Float32Array | null>(null)\n  const audioContext = useRef<AudioContext | null>(null)\n  const [blobUrl, blob]: any = useConvert(channelData)\n\n  useEffect(() => {\n    if (isRecording && stream) {\n      setChannelData(null)\n\n      audioContext.current = new AudioContext()\n      const context = audioContext.current\n\n      // https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createScriptProcessor\n      // bufferSize: the onaudioprocess event is called when the buffer is full\n      let recorder: ScriptProcessorNode\n      if (context.createScriptProcessor) {\n        recorder = context.createScriptProcessor(\n          bufferSize,\n          numberOfInputChannels,\n          numberOfOutputChannels\n        )\n      } else {\n        recorder = (context as any).createJavaScriptNode(\n          bufferSize,\n          numberOfInputChannels,\n          numberOfOutputChannels\n        )\n      }\n\n      recorder.onaudioprocess = function (e: any) {\n        const leftChannelData = new Float32Array(\n          e.inputBuffer.getChannelData(0)\n        )\n        leftChannel.current.push(leftChannelData)\n        // rightchannel.push(\n        //   new Float32Array(e.inputBuffer.getChannelData(1))\n        // );\n        recordingLength.current = recordingLength.current + bufferSize\n      }\n\n      setRecorder(recorder)\n      const mediaStream2 = context.createMediaStreamSource(stream)\n      setMediaStream(mediaStream2)\n      mediaStream2.connect(recorder)\n      recorder.connect(context.destination)\n    } else if (isRecording === false) {\n      if (recorder && mediaStream && audioContext.current) {\n        recorder && recorder.disconnect(audioContext.current.destination)\n        mediaStream && mediaStream.disconnect(recorder)\n        const data = flattenArray(leftChannel.current, recordingLength.current)\n        setChannelData(data)\n      }\n    }\n  }, [isRecording])\n\n  return { isRecording, setIsRecording, blobUrl, blob, channelData }\n}\n\nexport default useRecordMp3\n","export function flattenArray(channelBuffer: any, recordingLength: number) {\n  var result = new Float32Array(recordingLength)\n  var offset = 0\n  for (var i = 0; i < channelBuffer.length; i++) {\n    var buffer = channelBuffer[i]\n    result.set(buffer, offset)\n    offset += buffer.length\n  }\n  return result\n}\n\nexport function convertToArrayBuffer(blob: Blob) {\n  const url = URL.createObjectURL(blob)\n\n  return fetch(url).then((response) => {\n    return response.arrayBuffer()\n  })\n}\n\n// function process(data) {\n//   const blob = new Blob(data);\n\n//   convertToArrayBuffer(blob)\n//     .then((arrayBuffer) => audioContext.decodeAudioData(arrayBuffer))\n//     .then((audioBuffer) => {\n//       const channelData = audioBuffer.getChannelData(0);\n//       setChannelData(channelData);\n//     });\n// }\n","import React from 'react'\nimport useUserMedia from 'react-use-user-media'\nimport useRecordMp3 from 'use-record-mp3'\n\nconst constraints = {\n  // audio: true\n  audio: {\n    //   // sampleRate: 48000,\n    //   // sampleSize: 16,\n    channelCount: 2\n  }\n}\n\n// https://css-tricks.com/making-an-audio-waveform-visualizer-with-vanilla-javascript/\nconst filterData = (rawData: any) => {\n  // const rawData = audioBuffer.getChannelData(0); // We only need to work with one channel of data\n  const samples = 1000 // Number of samples we want to have in our final data set\n  const blockSize = Math.floor(rawData.length / samples) // the number of samples in each subdivision\n  const filteredData = []\n  for (let i = 0; i < samples; i++) {\n    let blockStart = blockSize * i // the location of the first sample in the block\n    let sum = 0\n    for (let j = 0; j < blockSize; j++) {\n      sum = sum + Math.abs(rawData[blockStart + j]) // find the sum of all the samples in the block\n    }\n    filteredData.push(sum / blockSize) // divide the sum by the block size to get the average\n  }\n  return filteredData\n}\n\n// const normalizeData = (filteredData: any) => {\n//   const multiplier = Math.pow(Math.max(...filteredData), -1)\n//   return filteredData.map((n: any) => n * multiplier)\n// }\n\nconst App = () => {\n  const { stream } = useUserMedia(constraints)\n  const { isRecording, setIsRecording, blobUrl, channelData } = useRecordMp3(\n    stream\n  )\n\n  const chart = channelData ? filterData(channelData) : []\n  const chartComponents = chart.map((number: number, index: number) => {\n    return (\n      <div\n        key={index}\n        style={{\n          width: '0.1%',\n          height: `${number * 100}%`,\n          backgroundColor: 'red'\n        }}\n      ></div>\n    )\n  })\n  return (\n    <div>\n      <button onClick={() => setIsRecording(!isRecording)}>\n        {isRecording ? 'Stop' : 'Record'}\n      </button>\n      {blobUrl && <audio controls src={blobUrl}></audio>}\n      <div\n        style={{\n          display: 'flex',\n          alignItems: 'center',\n          width: '300px',\n          height: '100px'\n        }}\n      >\n        {chartComponents}\n      </div>\n    </div>\n  )\n}\n\nexport default App\n","import './index.css'\n\nimport React from 'react'\nimport ReactDOM from 'react-dom'\nimport App from './App'\n\nReactDOM.render(<App />, document.getElementById('root'))\n"],"sourceRoot":""}